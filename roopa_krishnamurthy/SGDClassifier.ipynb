{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/opt/conda/lib/python36.zip',\n",
       " '/opt/conda/lib/python3.6',\n",
       " '/opt/conda/lib/python3.6/lib-dynload',\n",
       " '/opt/conda/lib/python3.6/site-packages',\n",
       " '/opt/conda/lib/python3.6/site-packages/Mako-1.0.7-py3.6.egg',\n",
       " '/opt/conda/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/home/jovyan/.ipython',\n",
       " '../src/',\n",
       " '../src/',\n",
       " '../src/',\n",
       " '../src/',\n",
       " '../src/',\n",
       " '../src/',\n",
       " '../src/',\n",
       " '../src/',\n",
       " '../src/',\n",
       " '../src/',\n",
       " '../src/',\n",
       " '../src/',\n",
       " '../src/']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, log_loss\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from numpy import sqrt, mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read in data and one-hot-encode int dtype variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../data/Series3_6.15.17_padel.csv\", index_col=0)\n",
    "# Eliminate features without variance\n",
    "df = df.loc[:, (df.std() > 0).values]\n",
    "# Seperate Series 3 test when IC50 is null\n",
    "test_index = df.IC50.isnull()\n",
    "test_df = df.loc[test_index]\n",
    "df = df.loc[~test_index]\n",
    "# Remove columns with missing data\n",
    "df = df.dropna(axis=1)\n",
    "# Transform discrete with one-hot-encoding\n",
    "int_cols = df.columns[df.dtypes == 'int64']\n",
    "float_cols = df.columns[df.dtypes == 'float64']\n",
    "one_hot_df = pd.get_dummies(df[int_cols].astype('O'))\n",
    "df = pd.merge(df[float_cols], one_hot_df, left_index=True, right_index=True)\n",
    "# Split x, y\n",
    "y_data = df.pop(\"IC50\")\n",
    "x_data = df.copy()\n",
    "# Ensure no (+/-) inf or nan due to improper transformation\n",
    "x_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "assert not sum(x_data.isna().sum()), \"Unexpected nulls found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform non-linear transformations to Series 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature engineering on float columns\n",
    "for feat in x_data.columns[x_data.dtypes == 'float64']:\n",
    "    feature_df = x_data.loc[:, feat]\n",
    "    if feature_df.min() > 0:  # Avoid 0 or negative\n",
    "        x_data.loc[:, feat + \"_log\"] = feature_df.apply(np.log)  # log\n",
    "        x_data.loc[:, feat + \"_log2\"] = feature_df.apply(np.log2)  # log2\n",
    "        x_data.loc[:, feat + \"_log10\"] = feature_df.apply(np.log10)  # log10\n",
    "        x_data.loc[:, feat + \"_cubert\"] = feature_df.apply(\n",
    "            lambda x: np.power(x, 1 / 3))  # cube root\n",
    "        x_data.loc[:, feat + \"_sqrt\"] = feature_df.apply(np.sqrt)  # square root\n",
    "    # Avoid extremely large values, keep around 1M max\n",
    "    if feature_df.max() < 13:\n",
    "        x_data.loc[:, feat + \"_exp\"] = feature_df.apply(np.exp)  # exp\n",
    "    if feature_df.max() < 20:\n",
    "        x_data.loc[:, feat + \"_exp2\"] = feature_df.apply(np.exp2)  # exp2\n",
    "    if feature_df.max() < 100:\n",
    "        x_data.loc[:, feat + \"_cube\"] = feature_df.apply(\n",
    "            lambda x: np.power(x, 3))  # cube\n",
    "    if feature_df.max() < 1000:\n",
    "        x_data.loc[:, feat + \"_sq\"] = feature_df.apply(np.square)  # square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_data = scale(x_data, with_mean=True)\n",
    "x_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_dim = PCA(n_components=350)\n",
    "pca_result = reduce_dim.fit_transform(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_pca = pd.DataFrame(data = pca_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform Grid-search to SelecyKBest PCA components and tune SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_scorer(x, y):\n",
    "    \"\"\"    \n",
    "    Get the variance for each column of X.\n",
    "    \n",
    "    Because principal components have decreasing variance\n",
    "    (i.e. PC4 has less variance than PC3 which has less variance\n",
    "    than PC2 etc.), we can use this function in SelectKBest to select\n",
    "    only the top X number of principal components.\n",
    "    \n",
    "    \"\"\"\n",
    "    scores = [np.var(column) for column in x.T]\n",
    "    return scores, np.array([np.NaN]*len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_regressor(x_data, y_data, model, add_train_data=None, verbose=1, pos_split=10):\n",
    "    \"\"\"\n",
    "    Model validation for producing comparable model evaluation. Uses Stratified K-Fold LOOCV adapted\n",
    "    for regression with the positive equivalent <10 IC50, producing 5 folds.\n",
    "    :param x_data: Pandas DataFrame object, Series 3 with 47 examples\n",
    "    :param y_data: Pandas DataFrame or Series object, float datatype, target variables for Series 3\n",
    "    :param model: must have fit and predict method, use sklearn or wrapper\n",
    "    :param add_train_data: Additional data to be evenly spread across train splits\n",
    "    :param verbose: If 0, return dictionary only, if 1 printed results\n",
    "    :param pos_split: cutoff for positive class in StratifiedKFold (y<pos_split)\n",
    "    :return: dictionary\n",
    "    \"\"\"\n",
    "    assert isinstance(x_data, DataFrame), \"x_data must be a pandas DataFrame\"\n",
    "    assert isinstance(y_data, DataFrame) or isinstance(y_data, Series), \"y_data must be pandas DataFrame or Series\"\n",
    "    assert y_data.dtypes == \"float\", \"Expected y_data to be float dtype and received {}\".format(y_data.dtypes)\n",
    "\n",
    "    if add_train_data is not None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # create logging dictionary to track scores\n",
    "    scoring_dict = {\"r2_score\": [], \"rmse\": []}\n",
    "    # create y_class series for Stratified K-Fold split at pos_split\n",
    "    y_class = Series(data=[int(y < pos_split) for y in y_data])\n",
    "    # num_splits count number of positive examples\n",
    "    num_splits = sum(y_class.values)\n",
    "    scoring_dict[\"num_splits\"] = num_splits\n",
    "    # create splits using stratified kfold\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=num_splits, n_repeats=10, random_state=36851234)\n",
    "    # loop through splits\n",
    "    for train, test in rskf.split(x_data, y_class):\n",
    "        x_train, x_test = x_data.iloc[train, :], x_data.iloc[test, :]\n",
    "        y_train, y_test = y_data.iloc[train], y_data.iloc[test]\n",
    "        # train model, test model with all scoring parameters\n",
    "        model.fit(x_train, y_train)\n",
    "        y_ = model.predict(x_test)\n",
    "        # append scores to logging dictionary\n",
    "        scoring_dict[\"r2_score\"].append(r2_score(y_test, y_))\n",
    "        scoring_dict[\"rmse\"].append(sqrt(mean_squared_error(y_test, y_)))\n",
    "    if verbose == 1:\n",
    "        # Print contents of dictionary except confusion matrix\n",
    "        print(\"with {} splits and {} repeats\".format(num_splits, 10))\n",
    "        for metric in scoring_dict:\n",
    "            if metric == \"num_splits\":\n",
    "                continue\n",
    "            else:\n",
    "                print(\"average {}: {}\".format(metric, mean(scoring_dict[metric])))\n",
    "    return scoring_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 5 splits and 10 repeats\n",
      "average r2_score: -0.20301890116385365\n",
      "average rmse: 29.567772540388663\n"
     ]
    }
   ],
   "source": [
    "results = score_regressor(x_data= x_data_pca, y_data = y_data, model = grid.best_estimator_)\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
